import { chromium } from "playwright";
import pLimit from "p-limit";
import similarity from "string-similarity";
import { seeds, listing, details } from "./selectors.config.js";

// ====== ENV ======
const APPS_SCRIPT_WEBHOOK = process.env.APPS_SCRIPT_WEBHOOK; // required to post rows
const JOB_TOKEN = process.env.JOB_TOKEN;                     // required (your shared secret)
const PROXY_URL = process.env.PROXY_URL || "";               // optional (ScraperAPI, etc.)

if (!APPS_SCRIPT_WEBHOOK) {
  console.error("Missing APPS_SCRIPT_WEBHOOK env var.");
  process.exit(1);
}
if (!JOB_TOKEN) {
  console.error("Missing JOB_TOKEN env var.");
  process.exit(1);
}

// ====== SETTINGS ======
const BRANDS = ["TagVenue", "HireSpace"];

const PAGE_TIMEOUT_MS = 90_000;
const NAV_WAIT = "networkidle"; // or "domcontentloaded" if needed
const PER_PAGE_PAUSE_MS = 1200; // polite pause between pages
const LIST_CONCURRENCY = 4;     // how many detail navigations in parallel (not used if we just collect links)
const MAX_EMPTY_PAGES = 3;      // stop if we see N consecutive pages with zero items
const MAX_PAGES_HARD = 300;     // absolute cap as a safety hatch

// ====== HELPERS ======
function normalizeKey(name, city) {
  return (name + "|" + (city || "")).toLowerCase().replace(/[^a-z0-9|]/g, "");
}

function isBotWall(html, title) {
  const t = (title || "").toLowerCase();
  if (t.includes("verify") || t.includes("checking your browser")) return true;
  if (/bot|blocked|unusual traffic|are you a human/i.test(html)) return true;
  return false;
}

function absolutize(href, base) {
  try {
    if (!href) return null;
    return href.startsWith("http") ? href : new URL(href, base).toString();
  } catch {
    return null;
  }
}

// ====== CRAWL ONE BRAND ======
async function crawlBrand(brand) {
  const seed = seeds[brand]?.[0];
  if (!seed) {
    console.warn(`[${brand}] no seed URL configured.`);
    return [];
  }
  const cfg = listing[brand];
  if (!cfg) {
    console.warn(`[${brand}] no listing config.`);
    return [];
  }

  console.log(`[${brand}] Using proxy: ${PROXY_URL ? "***" : "none"}`);

  const launchOpts = {
    args: ["--no-sandbox", "--disable-setuid-sandbox"],
    headless: true
  };
  if (PROXY_URL) {
    launchOpts.proxy = { server: PROXY_URL };
  }

  const browser = await chromium.launch(launchOpts);
  const page = await browser.newPage();

  const foundLinks = [];
  let url = seed;
  let pageNum = 0;
  let emptyStreak = 0;

  try {
    while (url && pageNum < MAX_PAGES_HARD) {
      pageNum++;
      console.log(`[${brand}] Visiting ${url}`);

      let resp;
      try {
        resp = await page.goto(url, { timeout: PAGE_TIMEOUT_MS, waitUntil: NAV_WAIT });
      } catch (e) {
        console.warn(`[${brand}] page ${pageNum} navigation error: ${e.message}`);
        break;
      }

      // Optional wait for content grid
      if (cfg.contentReadySelector) {
        try {
          await page.waitForSelector(cfg.contentReadySelector, { timeout: 15_000 });
        } catch {
          // carry on; we’ll still try to read links
        }
      }

      const title = (await page.title().catch(() => "")) || "";
      const html = await page.content().catch(() => "");

      if (isBotWall(html, title)) {
        console.warn(`[${brand}] page ${pageNum} looks like a verification/bot wall. Stopping.`);
        break;
      }

      // Extract venue links
      const links = await page.$$eval(
        cfg.venueLinkSelector,
        (as) => [...new Set(as.map((a) => (a && a.href ? a.href : null)).filter(Boolean))]
      ).catch(() => []);

      const absLinks = links
        .map((h) => absolutize(h, url))
        .filter(Boolean);

      console.log(`[${brand}] page ${pageNum} => items: ${absLinks.length}`);

      if (absLinks.length === 0) {
        emptyStreak++;
        if (emptyStreak >= MAX_EMPTY_PAGES) {
          console.log(`[${brand}] No links found on page ${pageNum} for ${emptyStreak} consecutive pages, stopping.`);
          break;
        }
      } else {
        emptyStreak = 0;
        foundLinks.push(...absLinks);
      }

      // Attempt to find next page
      let nextHref = null;
      try {
        // Prefer an explicit next button
        const nextHandle = await page.$(cfg.nextPageSelector);
        if (nextHandle) {
          const raw = await nextHandle.getAttribute("href");
          if (raw) nextHref = absolutize(raw, url);
        }
        // If not found, try page= increment
        if (!nextHref) {
          const u = new URL(url);
          const current = Number(u.searchParams.get("page") || "1");
          if (Number.isFinite(current)) {
            u.searchParams.set("page", String(current + 1));
            nextHref = u.toString();
          }
        }
      } catch {
        nextHref = null;
      }

      // Cheap terminal detection: if the “next” is same as current, stop
      if (!nextHref || nextHref === url) {
        console.log(`[${brand}] No next page detected. Stopping at page ${pageNum}.`);
        break;
      }

      // Small polite pause
      await new Promise((r) => setTimeout(r, PER_PAGE_PAUSE_MS));
      url = nextHref;
    }
  } finally {
    await page.close().catch(() => {});
    await browser.close().catch(() => {});
  }

  // Deduplicate links
  const unique = [...new Set(foundLinks)];
  console.log(`[${brand}] Total links found: ${unique.length}`);
  return unique.map((dirUrl) => ({ dirUrl, source: brand }));
}

// ====== POST ROWS TO APPS SCRIPT ======
async function postRows(rows) {
  if (!rows.length) return { ok: true, posted: 0 };

  const payload = {
    token: JOB_TOKEN,
    rows
  };

  const resp = await fetch(APPS_SCRIPT_WEBHOOK, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload)
  });

  const text = await resp.text().catch(() => "");
  if (!resp.ok) {
    console.error(`Apps Script responded ${resp.status}: ${text}`);
    return { ok: false, posted: 0, error: text };
  }
  let json = {};
  try { json = JSON.parse(text); } catch {}
  return { ok: true, posted: rows.length, response: json };
}

// ====== MAIN ======
async function run() {
  let total = 0;
  for (const brand of BRANDS) {
    const links = await crawlBrand(brand);

    if (!links.length) {
      console.log(`[${brand}] no rows to post.`);
      continue;
    }

    // We only have directory URLs here (no name/city yet). That’s OK if your
    // Apps Script / Sheet just stores dirUrl + source + fetchedAt for now.
    // If you want names/cities, add a per-link detail fetcher here.
    const rows = links.map((l) => ({
      name: "",    // left blank (we didn’t visit detail pages here)
      city: "",
      source: l.source,
      dirUrl: l.dirUrl,
      fetchedAt: new Date().toISOString()
    }));

    const res = await postRows(rows);
    if (res.ok) {
      total += res.posted;
      console.log(`[${brand}] posted rows: ${res.posted}`);
    } else {
      console.error(`[${brand}] failed to post rows: ${res.error || "unknown error"}`);
    }
  }
  console.log(`All done. Posted total rows: ${total}`);
}

run().catch((e) => {
  console.error(e);
  process.exit(1);
});
